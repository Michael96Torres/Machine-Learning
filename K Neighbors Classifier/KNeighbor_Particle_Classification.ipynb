{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** MAGIC Telescope (K-Neighbor Classifier) Report **\n",
    "\n",
    "##### This dataset has been cleaned to consist of telescope data including length, width, size, distance and particle classification.  Using this data and predictive modeling methods(K-Neighbor Classification), machine learning will be utilized for predictive classification of the radtioation particle (Gamma or Hadron).\n",
    "\n",
    "#### Link to Dataset: https://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>size</th>\n",
       "      <th>distance</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     length     width    size  distance class\n",
       "0   28.7967   16.0021  2.6449   81.8828     g\n",
       "1   31.6036   11.7235  2.5185  205.2610     g\n",
       "2  162.0520  136.0310  4.0612  256.7880     g\n",
       "3   23.8172    9.5728  2.3385  116.7370     g\n",
       "4   75.1362   30.9205  3.1611  356.4620     g"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataSet=pd.read_csv('GammaTelescopeDataCleaned.csv')\n",
    "X = dataSet.iloc[:,:-1]\n",
    "y = dataSet.iloc[:,4]\n",
    "dataSet.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 80% of the dataset for training and 20% for testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the First K Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_predicted=classifier.predict(X_test)\n",
    "y_predicted_proba=classifier.predict_proba(X_test)\n",
    "\n",
    "y_train_predicted=classifier.predict(X_train)\n",
    "y_train_predicted_proba=classifier.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics : Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           g       0.73      0.92      0.82      2460\n",
      "           h       0.73      0.38      0.50      1344\n",
      "\n",
      "    accuracy                           0.73      3804\n",
      "   macro avg       0.73      0.65      0.66      3804\n",
      "weighted avg       0.73      0.73      0.71      3804\n",
      "\n",
      "Confusion Matrix\n",
      "[[2275  185]\n",
      " [ 833  511]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test,y_predicted))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  73.23869610935857\n",
      "Sensitivity =  0.3802083333333333\n",
      "Specificity =  0.9247967479674797\n",
      "f1-score =  0.7323869610935857\n",
      "log loss =  5.752473288873\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \",accuracy_score(y_test,y_predicted)*100)\n",
    "print(\"Sensitivity = \", 511/(511+833))\n",
    "print(\"Specificity = \", 2275/(2275+185))\n",
    "print(\"f1-score = \",metrics.f1_score(y_test,y_predicted, average=\"micro\"))\n",
    "print(\"log loss = \", metrics.log_loss(y_test,y_predicted_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics : Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           g       0.80      1.00      0.89      9872\n",
      "           h       1.00      0.54      0.70      5344\n",
      "\n",
      "    accuracy                           0.84     15216\n",
      "   macro avg       0.90      0.77      0.80     15216\n",
      "weighted avg       0.87      0.84      0.82     15216\n",
      "\n",
      "Confusion Matrix\n",
      "[[9872    0]\n",
      " [2455 2889]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_train,y_train_predicted))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_train,y_train_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  83.86566771819138\n",
      "Sensitivity =  0.5406062874251497\n",
      "Specificity =  1.0\n",
      "f1-score =  0.8386566771819137\n",
      "log loss =  0.2161529555571077\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \",accuracy_score(y_train,y_train_predicted)*100)\n",
    "print(\"Sensitivity = \", 2889/(2889+2455))\n",
    "print(\"Specificity = \", 9872/(9872+0))\n",
    "print(\"f1-score = \",metrics.f1_score(y_train,y_train_predicted, average=\"micro\"))\n",
    "print(\"log loss = \", metrics.log_loss(y_train,y_train_predicted_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Second K Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_2 = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier_2.fit(X_train, y_train)\n",
    "\n",
    "y2_predicted=classifier_2.predict(X_test)\n",
    "y2_predicted_proba=classifier_2.predict_proba(X_test)\n",
    "\n",
    "y2_train_predicted=classifier_2.predict(X_train)\n",
    "y2_train_predicted_proba=classifier_2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics: Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           g       0.76      0.84      0.80      2460\n",
      "           h       0.64      0.52      0.57      1344\n",
      "\n",
      "    accuracy                           0.73      3804\n",
      "   macro avg       0.70      0.68      0.69      3804\n",
      "weighted avg       0.72      0.73      0.72      3804\n",
      "\n",
      "Confusion Matrix\n",
      "[[2068  392]\n",
      " [ 646  698]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, y2_predicted))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test,y2_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  72.71293375394322\n",
      "Sensitivity =  0.5193452380952381\n",
      "Specificity =  0.8406504065040651\n",
      "f1-score =  0.7271293375394322\n",
      "log loss =  3.692956713437581\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \",accuracy_score(y_test,y2_predicted)*100)\n",
    "print(\"Sensitivity = \", 698/(698+646))\n",
    "print(\"Specificity = \", 2068/(2068+392))\n",
    "print(\"f1-score = \",metrics.f1_score(y_test,y2_predicted, average=\"micro\"))\n",
    "print(\"log loss = \", metrics.log_loss(y_test,y2_predicted_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics: Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           g       0.85      0.92      0.88      9872\n",
      "           h       0.83      0.69      0.76      5344\n",
      "\n",
      "    accuracy                           0.84     15216\n",
      "   macro avg       0.84      0.81      0.82     15216\n",
      "weighted avg       0.84      0.84      0.84     15216\n",
      "\n",
      "Confusion Matrix\n",
      "[[9127  745]\n",
      " [1637 3707]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_train,y2_train_predicted))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_train,y2_train_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  84.34542586750788\n",
      "Sensitivity =  0.6936751497005988\n",
      "Specificity =  0.9245340356564019\n",
      "f1-score =  0.8434542586750788\n",
      "log loss =  0.3029811345338579\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \",accuracy_score(y_train,y2_train_predicted)*100)\n",
    "print(\"Sensitivity = \", 3707/(3707+1637))\n",
    "print(\"Specificity = \", 9127/(9127+745))\n",
    "print(\"f1-score = \",metrics.f1_score(y_train,y2_train_predicted, average=\"micro\"))\n",
    "print(\"log loss = \", metrics.log_loss(y_train,y2_train_predicted_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Third K Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_3 = KNeighborsClassifier(n_neighbors=4)\n",
    "classifier_3.fit(X_train, y_train)\n",
    "\n",
    "y3_predicted=classifier_3.predict(X_test)\n",
    "y3_predicted_proba=classifier_3.predict_proba(X_test)\n",
    "\n",
    "y3_train_predicted=classifier_3.predict(X_train)\n",
    "y3_train_predicted_proba=classifier_3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics: Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           g       0.74      0.92      0.82      2460\n",
      "           h       0.75      0.41      0.53      1344\n",
      "\n",
      "    accuracy                           0.74      3804\n",
      "   macro avg       0.74      0.67      0.67      3804\n",
      "weighted avg       0.74      0.74      0.72      3804\n",
      "\n",
      "Confusion Matrix\n",
      "[[2275  185]\n",
      " [ 798  546]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, y3_predicted))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test,y3_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  74.15878023133544\n",
      "Sensitivity =  0.40625\n",
      "Specificity =  0.9247967479674797\n",
      "f1-score =  0.7415878023133544\n",
      "log loss =  2.7731525241128194\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \",accuracy_score(y_test,y3_predicted)*100)\n",
    "print(\"Sensitivity = \", 546/(546+798))\n",
    "print(\"Specificity = \", 2275/(2275+185))\n",
    "print(\"f1-score = \",metrics.f1_score(y_test,y3_predicted, average=\"micro\"))\n",
    "print(\"log loss = \", metrics.log_loss(y_test,y3_predicted_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics: Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           g       0.79      0.97      0.87      9872\n",
      "           h       0.90      0.51      0.65      5344\n",
      "\n",
      "    accuracy                           0.81     15216\n",
      "   macro avg       0.84      0.74      0.76     15216\n",
      "weighted avg       0.82      0.81      0.79     15216\n",
      "\n",
      "Confusion Matrix\n",
      "[[9553  319]\n",
      " [2615 2729]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_train,y3_train_predicted))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_train,y3_train_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  80.71766561514195\n",
      "Sensitivity =  0.5106661676646707\n",
      "Specificity =  0.9676863857374393\n",
      "f1-score =  0.8071766561514195\n",
      "log loss =  0.3480804091228501\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \",accuracy_score(y_train,y3_train_predicted)*100)\n",
    "print(\"Sensitivity = \", 2729/(2729+2615))\n",
    "print(\"Specificity = \", 9553/(9553+319))\n",
    "print(\"f1-score = \",metrics.f1_score(y_train,y3_train_predicted, average=\"micro\"))\n",
    "print(\"log loss = \", metrics.log_loss(y_train,y3_train_predicted_proba))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8cddbd2c01e0d4287a9319bff02504c288603c9ff24efb01a7292be918eca2fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
